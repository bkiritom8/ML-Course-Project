{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1b8a77b4-e4c9-4064-96e0-16a47c9e3569",
      "metadata": {
        "id": "1b8a77b4-e4c9-4064-96e0-16a47c9e3569"
      },
      "outputs": [],
      "source": [
        "# Core Data Science\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_recall_fscore_support,\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    cohen_kappa_score, matthews_corrcoef\n",
        ")\n",
        "\n",
        "# Imbalanced learning\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Random seed for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a2161eeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2161eeb",
        "outputId": "2df29687-f6ad-4394-99b8-ea4f3977b877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Shape: (1042, 1004)\n",
            "  Rows (samples): 1042\n",
            "  Columns (features): 1004\n",
            "LAST 5 COLUMNS:\n",
            "['IL4I1', 'Age_Zscore', 'Sex_Male', 'Diagnosis', 'Dataset']\n",
            "DATASET COMPOSITION:\n",
            "\n",
            "By source:\n",
            "Dataset\n",
            "ADNI         700\n",
            "GSE110226    329\n",
            "GSE63060      13\n",
            "Name: count, dtype: int64\n",
            "\n",
            "By diagnosis:\n",
            "Diagnosis\n",
            "MCI        519\n",
            "Control    371\n",
            "AD         152\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Cross-tabulation (Dataset × Diagnosis):\n",
            "Diagnosis   AD  Control  MCI\n",
            "Dataset                     \n",
            "ADNI         0      261  439\n",
            "GSE110226  145      104   80\n",
            "GSE63060     7        6    0\n",
            "MISSING VALUES: 0\n",
            "No missing values\n"
          ]
        }
      ],
      "source": [
        "# Load and inspect the preprocessed dataset\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('Final_Dataset_with_dataset.csv')\n",
        "\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"  Rows (samples): {df.shape[0]}\")\n",
        "print(f\"  Columns (features): {df.shape[1]}\")\n",
        "\n",
        "# Check last columns (should be clinical + labels)\n",
        "print(\"LAST 5 COLUMNS:\")\n",
        "print(df.columns[-5:].tolist())\n",
        "\n",
        "# Dataset composition\n",
        "print(\"DATASET COMPOSITION:\")\n",
        "print(\"\\nBy source:\")\n",
        "print(df['Dataset'].value_counts())\n",
        "\n",
        "print(\"\\nBy diagnosis:\")\n",
        "print(df['Diagnosis'].value_counts())\n",
        "\n",
        "print(\"\\nCross-tabulation (Dataset × Diagnosis):\")\n",
        "print(pd.crosstab(df['Dataset'], df['Diagnosis']))\n",
        "\n",
        "# Check for missing values\n",
        "missing = df.isnull().sum().sum()\n",
        "print(f\"MISSING VALUES: {missing}\")\n",
        "if missing > 0:\n",
        "    print(\"Warning: Missing values detected\")\n",
        "else:\n",
        "    print(\"No missing values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6482496a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6482496a",
        "outputId": "ec14772c-6fb4-4905-e1eb-48a590b5bea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature matrix: (1042, 1002)\n",
            "  Features: 1002 (1000 genes + Age_Zscore + Sex_Male)\n",
            "\n",
            "Target vector: (1042,)\n",
            "  Classes: ['AD' 'Control' 'MCI']\n",
            "LABEL ENCODING:\n",
            "  AD         : 0  (152 samples)\n",
            "  Control    : 1  (371 samples)\n",
            "  MCI        : 2  (519 samples)\n",
            "STRATIFIED TRAIN/TEST SPLIT (80/20)\n",
            "\n",
            "Training set: 833 samples\n",
            "    AD        : 121 ( 14.5%)\n",
            "    Control   : 297 ( 35.7%)\n",
            "    MCI       : 415 ( 49.8%)\n",
            "\n",
            "Test set: 209 samples\n",
            "    AD        :  31 ( 14.8%)\n",
            "    Control   :  74 ( 35.4%)\n",
            "    MCI       : 104 ( 49.8%)\n",
            "CLASS IMBALANCE ANALYSIS:\n",
            "  Majority class: 415 samples\n",
            "  Minority class: 121 samples\n",
            "  Imbalance ratio: 3.43:1\n"
          ]
        }
      ],
      "source": [
        "# Prepare data for modeling\n",
        "\n",
        "# Separate features and target\n",
        "feature_cols = [col for col in df.columns if col not in ['Diagnosis', 'Dataset']]\n",
        "X = df[feature_cols].values\n",
        "y = df['Diagnosis'].values\n",
        "\n",
        "print(f\"\\nFeature matrix: {X.shape}\")\n",
        "print(f\"  Features: {X.shape[1]} (1000 genes + Age_Zscore + Sex_Male)\")\n",
        "\n",
        "print(f\"\\nTarget vector: {y.shape}\")\n",
        "print(f\"  Classes: {np.unique(y)}\")\n",
        "\n",
        "# Encode labels (AD=0, Control=1, MCI=2)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "print(\"LABEL ENCODING:\")\n",
        "for i, class_name in enumerate(le.classes_):\n",
        "    count = np.sum(y_encoded == i)\n",
        "    print(f\"  {class_name:10s} : {i}  ({count} samples)\")\n",
        "\n",
        "# Stratified train/test split BEFORE SMOTE\n",
        "print(\"STRATIFIED TRAIN/TEST SPLIT (80/20)\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded,\n",
        "    test_size=0.20,\n",
        "    stratify=y_encoded,  # Ensures balanced classes\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
        "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
        "for i, count in enumerate(train_dist):\n",
        "    class_name = le.inverse_transform([i])[0]\n",
        "    pct = 100 * count / len(y_train)\n",
        "    print(f\"    {class_name:10s}: {count:3d} ({pct:5.1f}%)\")\n",
        "\n",
        "print(f\"\\nTest set: {X_test.shape[0]} samples\")\n",
        "test_dist = pd.Series(y_test).value_counts().sort_index()\n",
        "for i, count in enumerate(test_dist):\n",
        "    class_name = le.inverse_transform([i])[0]\n",
        "    pct = 100 * count / len(y_test)\n",
        "    print(f\"    {class_name:10s}: {count:3d} ({pct:5.1f}%)\")\n",
        "\n",
        "# Calculate imbalance ratio\n",
        "print(\"CLASS IMBALANCE ANALYSIS:\")\n",
        "imbalance_ratio = train_dist.max() / train_dist.min()\n",
        "print(f\"  Majority class: {train_dist.max()} samples\")\n",
        "print(f\"  Minority class: {train_dist.min()} samples\")\n",
        "print(f\"  Imbalance ratio: {imbalance_ratio:.2f}:1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "765befbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "765befbf",
        "outputId": "64df51ad-5e01-49cf-e1c2-b4ba6e8e93ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "BEFORE SMOTE:\n",
            "  Training set: 833 samples\n",
            "    AD        : 121 samples\n",
            "    Control   : 297 samples\n",
            "    MCI       : 415 samples\n",
            "\n",
            "AFTER SMOTE:\n",
            "  Training set: 1245 samples\n",
            "    AD        : 415 samples (+294 synthetic)\n",
            "    Control   : 415 samples (+118 synthetic)\n",
            "    MCI       : 415 samples (+0 synthetic)\n",
            "\n",
            "Test set: 209 samples (UNCHANGED)\n",
            "  No synthetic data in test set (proper evaluation!)\n",
            "SUMMARY:\n",
            "  Original training samples: 833\n",
            "  After SMOTE: 1245\n",
            "  Synthetic samples added: 412\n",
            "  Test samples: 209 (unchanged)\n"
          ]
        }
      ],
      "source": [
        "# Apply SMOTE to training data\n",
        "\n",
        "# Store original training set info\n",
        "print(f\"\\nBEFORE SMOTE:\")\n",
        "print(f\"  Training set: {X_train.shape[0]} samples\")\n",
        "original_train_dist = pd.Series(y_train).value_counts().sort_index()\n",
        "for i, count in enumerate(original_train_dist):\n",
        "    class_name = le.inverse_transform([i])[0]\n",
        "    print(f\"    {class_name:10s}: {count:3d} samples\")\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=RANDOM_STATE)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"\\nAFTER SMOTE:\")\n",
        "print(f\"  Training set: {X_train_resampled.shape[0]} samples\")\n",
        "resampled_train_dist = pd.Series(y_train_resampled).value_counts().sort_index()\n",
        "for i, count in enumerate(resampled_train_dist):\n",
        "    class_name = le.inverse_transform([i])[0]\n",
        "    synthetic = count - original_train_dist.iloc[i]\n",
        "    print(f\"    {class_name:10s}: {count:3d} samples (+{synthetic} synthetic)\")\n",
        "\n",
        "print(f\"\\nTest set: {X_test.shape[0]} samples (UNCHANGED)\")\n",
        "print(\"  No synthetic data in test set (proper evaluation!)\")\n",
        "\n",
        "print(\"SUMMARY:\")\n",
        "print(f\"  Original training samples: {X_train.shape[0]}\")\n",
        "print(f\"  After SMOTE: {X_train_resampled.shape[0]}\")\n",
        "print(f\"  Synthetic samples added: {X_train_resampled.shape[0] - X_train.shape[0]}\")\n",
        "print(f\"  Test samples: {X_test.shape[0]} (unchanged)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
